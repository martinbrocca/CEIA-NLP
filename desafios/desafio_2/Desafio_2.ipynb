{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZd5yLnnHOK0"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Custom embedddings con Gensim\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vA7nqkumo9z9"
   },
   "source": [
    "### Objetivo\n",
    "El objetivo es utilizar documentos / corpus para crear embeddings de palabras basado en ese contexto. Se utilizará canciones de bandas para generar los embeddings, es decir, que los vectores tendrán la forma en función de como esa banda haya utilizado las palabras en sus canciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lFToQs5FK5uZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaXV6nlHr5Aa"
   },
   "source": [
    "#### - Función de callback definida en clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "OSb0v7h8r7hK"
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "# Durante el entrenamiento gensim por defecto no informa el \"loss\" en cada época\n",
    "# Sobrecargamos el callback para poder tener esta información\n",
    "class callback(CallbackAny2Vec):\n",
    "    \"\"\"\n",
    "    Callback to print loss after each epoch\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMM_SHSaZ9N-"
   },
   "source": [
    "### Desafío 2 - Consignas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WivQZ3ZCZ9N_"
   },
   "source": [
    "- Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.\n",
    "- Probar términos de interés y explicar similitudes en el espacio de embeddings (sacar conclusiones entre palabras similitudes y diferencias).\n",
    "- Graficarlos.\n",
    "- Obtener conclusiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolución del desafío"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio \n",
    "- Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          filename  \\\n",
      "0      1-Harry-Potter-and-the-Sorcerer’s-Stone.txt   \n",
      "1    2-Harry-Potter-and-the-Chamber-of-Secrets.txt   \n",
      "2   3-Harry-Potter-and-the-Prisoner-of-Azkaban.txt   \n",
      "3        4-Harry-Potter-and-the-Goblet-of-Fire.txt   \n",
      "4  5-Harry-Potter-and-the-Order-of-the-Phoenix.txt   \n",
      "\n",
      "                                             content  \n",
      "0  FOR JESSICA, WHO LOVES STORIES,\\n\\nFOR ANNE, W...  \n",
      "1  FOR SEÁN P. F. HARRIS,\\n\\nGETAWAY DRIVER AND F...  \n",
      "2  TO JILL PREWETT AND\\n\\nAINE KIELY,\\n\\nTHE GODM...  \n",
      "3  TO PETER ROWLING,\\n\\nIN MEMORY OF MR. RIDLEY\\n...  \n",
      "4  TO NEIL, JESSICA, AND DAVID,\\n\\nWHO MAKE MY WO...  \n"
     ]
    }
   ],
   "source": [
    "# Elijo como dataset las novelas de Harry Potter disponibles Hugging Face\n",
    "\n",
    "\n",
    "# Load dataset from HF\n",
    "dataset = load_dataset(\"elricwan/HarryPotter\", split=\"train\")\n",
    "\n",
    "# Convert to pandas DataFrame if needed\n",
    "df_HarryPotter = dataset.to_pandas()\n",
    "\n",
    "print(df_HarryPotter.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de documentos: 8\n",
      "Nombre de las columnas del DF:  Index(['filename', 'content'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de documentos:\", df_HarryPotter.shape[0])\n",
    "print(\"Nombre de las columnas del DF: \", df_HarryPotter.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observaciones:\n",
    "El dataset presenta 8 archivos de texto correspondientes a los 8 libros de Harry Potter.\n",
    "Debido a las diferencias con el dataset visto en clase, se utilizarán las siguientes definiciones:\n",
    " 1) Se concatenarán todos los libros para formar el corpus.\n",
    " 2) Se considerarán a los párrafos como los documentos para realizar los embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 'documents': 80066\n",
      "First doc: ['jessica', 'loves', 'stories']\n"
     ]
    }
   ],
   "source": [
    "# Verificar los documentos, y si se puede dividirlos en párrafos\n",
    "sentence_tokens_hp = []\n",
    "\n",
    "for book in df_HarryPotter['content']:\n",
    "    paragraphs = book.split(\"\\n\")  # Dividir el texto en párrafos usando el salto de línea como separador\n",
    "    for paragraph in paragraphs:\n",
    "        tokens = preprocess_text(paragraph)\n",
    "        if tokens:  # Solo agregar si no está vacío\n",
    "            sentence_tokens_hp.append(tokens)\n",
    "\n",
    "print(f\"Total 'documents': {len(sentence_tokens_hp)}\")\n",
    "print(\"First doc:\", sentence_tokens_hp[0][:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Remueve puntuación, convierte a minúsculas, elimina stopwords y tokeniza el texto.\n",
    "    \"\"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Keep only alphabetic characters and spaces\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Split into words\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Analisis del impacto de limpiar el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens únicos (en texto completo): 2238\n",
      "Tokens únicos (en texto limpio): 1628\n"
     ]
    }
   ],
   "source": [
    "raw_tokens = [word for sentence in df[0] for word in sentence.split()]\n",
    "clean_tokens = [word for sentence in sentence_tokens for word in sentence]\n",
    "\n",
    "print(\"Tokens únicos (en texto completo):\", len(set(raw_tokens)))\n",
    "print(\"Tokens únicos (en texto limpio):\", len(set(clean_tokens)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords antes: 6723\n",
      "Stopwords después: 7053\n",
      "Stopwords normalizados después: 7053\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "raw_tokens_norm = [re.sub(r'[^a-z]', '', w.lower()) for w in raw_tokens if w.strip() != '']\n",
    "\n",
    "stop_before = sum(1 for w in raw_tokens if w.lower() in stop_words)\n",
    "stop_after  = sum(1 for w in clean_tokens if w.lower() in stop_words)\n",
    "stop_before_norm = sum(1 for w in raw_tokens_norm if w in stop_words)\n",
    "\n",
    "print(\"Stopwords antes:\", stop_before)\n",
    "print(\"Stopwords después:\", stop_after)\n",
    "print(\"Stopwords normalizados después:\", stop_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo de párrafo tokenizado: ['jessica', 'loves', 'stories']\n",
      "Total de párrafos procesados: 80570\n"
     ]
    }
   ],
   "source": [
    "# Aplicar el preprocesamiento a cada parragrafo\n",
    "# 1) Concatenar todo el texto\n",
    "all_text = \" \".join(df_HarryPotter['content'].tolist())\n",
    "\n",
    "# Separar por párrafos\n",
    "paragraphs = all_text.split(\"\\n\\n\")\n",
    "\n",
    "# Preprocesar cada párrafo\n",
    "sentence_tokens_hp = [preprocess_text(p) for p in paragraphs if p.strip()]\n",
    "\n",
    "print(\"Ejemplo de párrafo tokenizado:\", sentence_tokens_hp[0][:30])\n",
    "print(\"Total de párrafos procesados:\", len(sentence_tokens_hp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model_hp_potter = Word2Vec(\n",
    "    sentences=sentence_tokens_hp,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    workers=4,\n",
    "    sg=1 # modelo 0:CBOW  1:skipgram\n",
    ")\n",
    "model_hp_potter_cbow = Word2Vec(\n",
    "    sentences=sentence_tokens_hp,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    workers=4,\n",
    "    sg=0 # modelo 0:CBOW  1:skipgram\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el vocabulario con los tokens\n",
    "model_hp_potter.build_vocab(sentence_tokens_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de docs en el corpus: 80570\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de filas/docs encontradas en el corpus\n",
    "print(\"Cantidad de docs en el corpus:\", model_hp_potter.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de words distintas en el corpus: 12352\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de words encontradas en el corpus\n",
    "print(\"Cantidad de words distintas en el corpus:\", len(model_hp_potter.wv.index_to_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 3503233.0\n",
      "Loss after epoch 1: 2937823.5\n",
      "Loss after epoch 2: 2681756.5\n",
      "Loss after epoch 3: 2371201.0\n",
      "Loss after epoch 4: 2366963.0\n",
      "Loss after epoch 5: 2357709.0\n",
      "Loss after epoch 6: 2147794.0\n",
      "Loss after epoch 7: 2027990.0\n",
      "Loss after epoch 8: 2020886.0\n",
      "Loss after epoch 9: 2001460.0\n",
      "Loss after epoch 10: 2002642.0\n",
      "Loss after epoch 11: 1986294.0\n",
      "Loss after epoch 12: 1981168.0\n",
      "Loss after epoch 13: 1982456.0\n",
      "Loss after epoch 14: 1628368.0\n",
      "Loss after epoch 15: 1085440.0\n",
      "Loss after epoch 16: 1100964.0\n",
      "Loss after epoch 17: 1090916.0\n",
      "Loss after epoch 18: 1089840.0\n",
      "Loss after epoch 19: 1064960.0\n",
      "Loss after epoch 20: 893336.0\n",
      "Loss after epoch 21: 1068716.0\n",
      "Loss after epoch 22: 1072112.0\n",
      "Loss after epoch 23: 1056140.0\n",
      "Loss after epoch 24: 1059964.0\n",
      "Loss after epoch 25: 1050528.0\n",
      "Loss after epoch 26: 1051356.0\n",
      "Loss after epoch 27: 1052940.0\n",
      "Loss after epoch 28: 1066980.0\n",
      "Loss after epoch 29: 1068544.0\n",
      "Loss after epoch 30: 1085396.0\n",
      "Loss after epoch 31: 1089020.0\n",
      "Loss after epoch 32: 1110748.0\n",
      "Loss after epoch 33: 1112188.0\n",
      "Loss after epoch 34: 1162540.0\n",
      "Loss after epoch 35: 1170108.0\n",
      "Loss after epoch 36: 1201396.0\n",
      "Loss after epoch 37: 1208924.0\n",
      "Loss after epoch 38: 1228976.0\n",
      "Loss after epoch 39: 1251848.0\n",
      "Loss after epoch 40: 1264644.0\n",
      "Loss after epoch 41: 1277652.0\n",
      "Loss after epoch 42: 1289024.0\n",
      "Loss after epoch 43: 1311280.0\n",
      "Loss after epoch 44: 617552.0\n",
      "Loss after epoch 45: 197080.0\n",
      "Loss after epoch 46: 189664.0\n",
      "Loss after epoch 47: 179856.0\n",
      "Loss after epoch 48: 171344.0\n",
      "Loss after epoch 49: 156328.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55162911, 60602400)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos el modelo generador de vectores\n",
    "# Utilizamos nuestro callback\n",
    "model_hp_potter.train(sentence_tokens_hp,\n",
    "                 total_examples=w2v_model.corpus_count,\n",
    "                 epochs=50,\n",
    "                 compute_loss = True,\n",
    "                 callbacks=[callback()]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 546048.375\n",
      "Loss after epoch 1: 469516.4375\n",
      "Loss after epoch 2: 520521.5625\n",
      "Loss after epoch 3: 487731.75\n",
      "Loss after epoch 4: 507766.625\n",
      "Loss after epoch 5: 493227.5\n",
      "Loss after epoch 6: 465416.25\n",
      "Loss after epoch 7: 434441.75\n",
      "Loss after epoch 8: 432383.75\n",
      "Loss after epoch 9: 357794.0\n",
      "Loss after epoch 10: 322038.5\n",
      "Loss after epoch 11: 333998.0\n",
      "Loss after epoch 12: 168370.5\n",
      "Loss after epoch 13: 179588.0\n",
      "Loss after epoch 14: 382377.0\n",
      "Loss after epoch 15: 381471.0\n",
      "Loss after epoch 16: 390082.5\n",
      "Loss after epoch 17: 352922.5\n",
      "Loss after epoch 18: 363715.0\n",
      "Loss after epoch 19: 385628.5\n",
      "Loss after epoch 20: 383850.0\n",
      "Loss after epoch 21: 340768.5\n",
      "Loss after epoch 22: 351275.0\n",
      "Loss after epoch 23: 304610.0\n",
      "Loss after epoch 24: 345722.0\n",
      "Loss after epoch 25: 333838.0\n",
      "Loss after epoch 26: 348242.0\n",
      "Loss after epoch 27: 335389.0\n",
      "Loss after epoch 28: 268151.0\n",
      "Loss after epoch 29: 334728.0\n",
      "Loss after epoch 30: 335820.0\n",
      "Loss after epoch 31: 335066.0\n",
      "Loss after epoch 32: 343546.0\n",
      "Loss after epoch 33: 347495.0\n",
      "Loss after epoch 34: 337459.0\n",
      "Loss after epoch 35: 338391.0\n",
      "Loss after epoch 36: 336670.0\n",
      "Loss after epoch 37: 317415.0\n",
      "Loss after epoch 38: 342653.0\n",
      "Loss after epoch 39: 321819.0\n",
      "Loss after epoch 40: 351488.0\n",
      "Loss after epoch 41: 296036.0\n",
      "Loss after epoch 42: 340917.0\n",
      "Loss after epoch 43: 313558.0\n",
      "Loss after epoch 44: 350980.0\n",
      "Loss after epoch 45: 342022.0\n",
      "Loss after epoch 46: 300178.0\n",
      "Loss after epoch 47: 264186.0\n",
      "Loss after epoch 48: 264066.0\n",
      "Loss after epoch 49: 260812.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55163212, 60602400)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos ahora el modelo CBOW\n",
    "model_hp_potter_cbow.train(sentence_tokens_hp,\n",
    "                 total_examples=w2v_model.corpus_count,\n",
    "                 epochs=50,\n",
    "                 compute_loss = True,\n",
    "                 callbacks=[callback()]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedemos a ensayar y a buscar relaciones de palabras en los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#función para imprimir los resultados de skipgram y CBOW\n",
    "def print_similar_words(skipgram, cbow ):\n",
    "    # Convert to DataFrame\n",
    "        df_compare = pd.DataFrame({\n",
    "            \"Skipgram\": [f\"{w} ({s:.3f})\" for w, s in skipgram],\n",
    "            \"CBOW\": [f\"{w} ({s:.3f})\" for w, s in cbow]\n",
    "        })\n",
    "\n",
    "        # Show as Markdown table\n",
    "        from tabulate import tabulate\n",
    "        print(tabulate(df_compare, headers=\"keys\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Skipgram             | CBOW             |\n",
      "|----|----------------------|------------------|\n",
      "|  0 | skeptical (0.749)    | ron (0.606)      |\n",
      "|  1 | retort (0.741)       | hermione (0.492) |\n",
      "|  2 | resentfully (0.738)  | hed (0.443)      |\n",
      "|  3 | tactless (0.736)     | hagrid (0.409)   |\n",
      "|  4 | aghast (0.728)       | cho (0.408)      |\n",
      "|  5 | wideeyed (0.726)     | back (0.404)     |\n",
      "|  6 | jovially (0.722)     | hadnt (0.397)    |\n",
      "|  7 | doubtfully (0.722)   | harrys (0.390)   |\n",
      "|  8 | gits (0.722)         | wood (0.383)     |\n",
      "|  9 | apprehensive (0.718) | ribs (0.381)     |\n"
     ]
    }
   ],
   "source": [
    "# Palabras que MÁS se relacionan con...: (skigram vs CBOW)\n",
    "skipgram = model_hp_potter.wv.most_similar(positive=[\"harry\"], topn=10)\n",
    "cbow = model_hp_potter_cbow.wv.most_similar(positive=[\"harry\"], topn=10)\n",
    "print_similar_words(skipgram, cbow )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observación:\n",
    "- Es correcta la proximidad de Ron y Hermione a Harry en cbow, dado que los tres conforman el trio principal para toda la aventura. Esto refuerza el concepto que Cbow se enfoca en asociaciones directas, reflejadas en las relaciones de Harry\n",
    "- Skipgram posee un foco sobre las palabras que dan contexto alrededor de la palabra target, lo que refleja una asociación fuerte con las emociones o acciones de, en este caso, el personaje principal.\n",
    "- Es interesante el hecho de que la onomatopeya \"shhhh\" se encuentre en tercer lugar. Siempre lo callan an pobre de Harry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Skipgram         | CBOW                 |\n",
      "|----|------------------|----------------------|\n",
      "|  0 | scarlet (0.106)  | sight (0.357)        |\n",
      "|  1 | became (0.088)   | wham (0.350)         |\n",
      "|  2 | curled (0.067)   | deliberately (0.349) |\n",
      "|  3 | crack (0.066)    | delight (0.348)      |\n",
      "|  4 | sobbing (0.059)  | wildly (0.348)       |\n",
      "|  5 | floor (0.046)    | snarl (0.345)        |\n",
      "|  6 | shrieked (0.039) | curlyhaired (0.345)  |\n",
      "|  7 | tears (0.039)    | bandylegged (0.340)  |\n",
      "|  8 | laughter (0.036) | whimper (0.335)      |\n",
      "|  9 | cho (0.036)      | smiles (0.332)       |\n"
     ]
    }
   ],
   "source": [
    "# Palabras que MENOS se relacionan con...:\n",
    "print_similar_words(model_hp_potter.wv.most_similar(negative=[\"magic\"], topn=10), model_hp_potter_cbow.wv.most_similar(negative=[\"magic\"], topn=10) ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Skipgram             | CBOW                 |\n",
      "|----|----------------------|----------------------|\n",
      "|  0 | voldemorts (0.732)   | voldemorts (0.709)   |\n",
      "|  1 | lord (0.651)         | youknowwhos (0.515)  |\n",
      "|  2 | equal (0.642)        | prophecy (0.489)     |\n",
      "|  3 | youknowwhos (0.615)  | youknowwho (0.472)   |\n",
      "|  4 | nagini (0.605)       | bellatrix (0.465)    |\n",
      "|  5 | feared (0.604)       | grindelwald (0.448)  |\n",
      "|  6 | survived (0.593)     | parseltongue (0.441) |\n",
      "|  7 | killing (0.591)      | wormtail (0.440)     |\n",
      "|  8 | parseltongue (0.588) | hallows (0.429)      |\n",
      "|  9 | bertha (0.586)       | connection (0.421)   |\n"
     ]
    }
   ],
   "source": [
    "# Palabras que MÁS se relacionan con...:\n",
    "print_similar_words(model_hp_potter.wv.most_similar(positive=[\"voldemort\"], topn=10), model_hp_potter_cbow.wv.most_similar(positive=[\"voldemort\"], topn=10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'flor' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Ensayar con una palabra que no está en el vocabulario:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mw2v_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmost_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnegative\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mflor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CEIA/CEIA-NLP/.venv/lib/python3.11/site-packages/gensim/models/keyedvectors.py:841\u001b[39m, in \u001b[36mKeyedVectors.most_similar\u001b[39m\u001b[34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[39m\n\u001b[32m    838\u001b[39m         weight[idx] = item[\u001b[32m1\u001b[39m]\n\u001b[32m    840\u001b[39m \u001b[38;5;66;03m# compute the weighted average of all keys\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m mean = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_mean_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_normalize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_normalize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_missing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m all_keys = [\n\u001b[32m    843\u001b[39m     \u001b[38;5;28mself\u001b[39m.get_index(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, _KEY_TYPES) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.has_index_for(key)\n\u001b[32m    844\u001b[39m ]\n\u001b[32m    846\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(topn, \u001b[38;5;28mint\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CEIA/CEIA-NLP/.venv/lib/python3.11/site-packages/gensim/models/keyedvectors.py:518\u001b[39m, in \u001b[36mKeyedVectors.get_mean_vector\u001b[39m\u001b[34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[39m\n\u001b[32m    516\u001b[39m         total_weight += \u001b[38;5;28mabs\u001b[39m(weights[idx])\n\u001b[32m    517\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_missing:\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKey \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not present in vocabulary\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    520\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total_weight > \u001b[32m0\u001b[39m:\n\u001b[32m    521\u001b[39m     mean = mean / total_weight\n",
      "\u001b[31mKeyError\u001b[39m: \"Key 'flor' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "# Ensayar con una palabra que no está en el vocabulario:\n",
    "w2v_model.wv.most_similar(negative=[\"flor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Skipgram              | CBOW             |\n",
      "|----|-----------------------|------------------|\n",
      "|  0 | kings (0.803)         | road (0.527)     |\n",
      "|  1 | cross (0.764)         | london (0.472)   |\n",
      "|  2 | road (0.744)          | yard (0.463)     |\n",
      "|  3 | charing (0.739)       | charing (0.437)  |\n",
      "|  4 | ticket (0.720)        | town (0.432)     |\n",
      "|  5 | threequarters (0.701) | train (0.418)    |\n",
      "|  6 | town (0.688)          | kings (0.413)    |\n",
      "|  7 | burrow (0.687)        | bustle (0.403)   |\n",
      "|  8 | london (0.686)        | lane (0.398)     |\n",
      "|  9 | platform (0.686)      | wisteria (0.385) |\n"
     ]
    }
   ],
   "source": [
    "# Palabras que MÁS se relacionan con...:\n",
    "print_similar_words( model_hp_potter.wv.most_similar(positive=[\"station\"], topn=10), model_hp_potter_cbow.wv.most_similar(positive=[\"station\"], topn=10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.50663412e-01 -1.52389482e-01 -2.83300012e-01 -1.30949676e-01\n",
      "  2.27266535e-01 -3.01922768e-01  2.74379283e-01  7.44201303e-01\n",
      " -1.17931515e-01 -2.36827713e-02 -5.01735091e-01  6.31573349e-02\n",
      "  2.43052617e-01  4.56351519e-01  4.09058452e-01 -3.01888939e-02\n",
      "  1.53085575e-01  1.48005545e-01 -5.28157830e-01 -1.33686781e-01\n",
      " -1.32122695e-01  7.00680494e-01 -2.92728422e-04 -4.66681510e-01\n",
      " -6.85469881e-02 -3.95182103e-01  2.48562083e-01 -8.27288449e-01\n",
      " -4.32975233e-01  1.09445110e-01  5.91463149e-01 -7.13975728e-03\n",
      "  1.46514401e-01 -4.52105403e-01  1.83359265e-01  3.31424057e-01\n",
      " -2.69755155e-01 -2.91276127e-01 -4.82715160e-01 -7.07179368e-01\n",
      "  3.65084410e-02 -3.25013041e-01  4.01991397e-01  2.10347306e-02\n",
      "  8.13915357e-02 -1.65663213e-01  9.40462425e-02 -2.03326911e-01\n",
      "  4.37827379e-01  5.93954504e-01 -5.07086098e-01 -1.13183837e-02\n",
      " -3.08690041e-01  1.19622327e-01  1.82093233e-01  2.16655135e-02\n",
      " -2.44084865e-01 -4.95229393e-01 -5.94993532e-02 -1.68379575e-01\n",
      "  3.15947533e-02  6.68947339e-01 -1.24536917e-01  1.07681617e-01\n",
      "  4.73572731e-01 -3.84424403e-02  6.55712962e-01  4.74476278e-01\n",
      " -4.63481635e-01  1.01345830e-01  9.00353715e-02 -3.60769629e-01\n",
      "  4.42433059e-01  8.25322390e-01  1.68506250e-01  6.77687466e-01\n",
      "  3.77070516e-01 -6.92417026e-02 -1.45978272e-01 -2.29405656e-01\n",
      " -1.98901892e-01  7.54299581e-01 -5.03341079e-01  9.80155692e-02\n",
      "  1.14033438e-01  1.42433196e-01  2.84079969e-01  3.54720443e-01\n",
      "  1.21390320e-01 -6.43116841e-03 -1.94131769e-02 -3.49143773e-01\n",
      " -1.01895496e-01  5.75128235e-02  9.34152231e-02  4.52941865e-01\n",
      " -2.05267504e-01  5.26360512e-01  1.52958423e-01 -2.77311891e-01]\n"
     ]
    }
   ],
   "source": [
    "# el método `get_vector` permite obtener los vectores:\n",
    "vector_potter = model_hp_potter.wv.get_vector(\"potter\")\n",
    "print(vector_potter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de los vectores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    \n",
    "from sklearn.manifold import TSNE                   \n",
    "import numpy as np                                  \n",
    "\n",
    "def reduce_dimensions(model, num_dimensions = 2 ):\n",
    "     \n",
    "    vectors = np.asarray(model.wv.vectors)\n",
    "    labels = np.asarray(model.wv.index_to_key)  \n",
    "\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    return vectors, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "model=Skip-gram<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>",
         "legendgroup": "Skip-gram",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Skip-gram",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "harry",
          "said",
          "ron",
          "hermione",
          "back",
          "dumbledore",
          "could",
          "one",
          "like",
          "looked",
          "would",
          "know",
          "around",
          "well",
          "got",
          "professor",
          "see",
          "dont",
          "though",
          "think",
          "still",
          "time",
          "hagrid",
          "get",
          "right",
          "eyes",
          "wand",
          "looking",
          "snape",
          "face",
          "voice",
          "weasley",
          "going",
          "harrys",
          "look",
          "go",
          "didnt",
          "room",
          "im",
          "come",
          "head",
          "door",
          "thought",
          "mr",
          "something",
          "potter",
          "saw",
          "malfoy",
          "never",
          "behind",
          "seemed",
          "hand",
          "way",
          "away",
          "hes",
          "told",
          "asked",
          "turned",
          "two",
          "last",
          "toward",
          "much",
          "dark",
          "little",
          "us",
          "long",
          "even",
          "voldemort",
          "sirius",
          "knew",
          "first",
          "good",
          "want",
          "oh",
          "tell",
          "heard",
          "made",
          "people",
          "hogwarts",
          "left",
          "yes",
          "really",
          "say",
          "moment",
          "felt",
          "mrs",
          "youre",
          "fred",
          "great",
          "black",
          "might",
          "thats",
          "ive",
          "front",
          "ever",
          "came",
          "death",
          "feet",
          "take",
          "anything",
          "sure",
          "lupin",
          "next",
          "nothing",
          "took",
          "trying",
          "three",
          "make",
          "another",
          "cant",
          "let",
          "george",
          "yeah",
          "table",
          "open",
          "old",
          "ginny",
          "inside",
          "went",
          "find",
          "mcgonagall",
          "must",
          "course",
          "neville",
          "magic",
          "large",
          "put",
          "ill",
          "school",
          "floor",
          "upon",
          "every",
          "thing",
          "hall",
          "gave",
          "seen",
          "place",
          "found",
          "hands",
          "stood",
          "hear",
          "need",
          "night",
          "without",
          "ministry",
          "onto",
          "house",
          "uncle",
          "mean",
          "pulled",
          "end",
          "gryffindor",
          "years",
          "across",
          "quite",
          "hair",
          "wanted",
          "bit",
          "boy",
          "air",
          "hed",
          "wasnt",
          "better",
          "cloak",
          "done",
          "happened",
          "umbridge",
          "couldnt",
          "help",
          "side",
          "keep",
          "enough",
          "man",
          "rons",
          "second",
          "along",
          "bed",
          "give",
          "fudge",
          "mind",
          "wizard",
          "light",
          "yet",
          "already",
          "youve",
          "whats",
          "small",
          "vernon",
          "however",
          "year",
          "robes",
          "staring",
          "gone",
          "else",
          "many",
          "rather",
          "set",
          "walked",
          "fell",
          "forward"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": {
          "bdata": "LUwoQTnNgkGL4SpB70Q1QHVPpsATF/dBxs0yQRonT0DecCNAeqJqwaH370FbsrtBkWLCwKs/rUEoxiBBkqKQQA5MP0HGRNBBwxUzQK1FwkEY37m/Nr4oQU2plEGA9qRBhahTQZwsAcLFyBLBLiBiwQFfksCNIcjBHzjzQOzOmkHnXPFBYt88wUGUEUBUM8ZBKTTiQYf0LMGN37dBeDKzQa3wfsHycbzB3rJ4QRQOmkG6dKpBSgn1QVyEa8FEJ/7AYBYEQhQbi8GfpyBBLE+mwRuc18AiTs7BgbzeQQRS2UEFeIlBAt+NwB1JcT9pIotBFIzGwYlU9EEfx65BQ+6KQG+67UFk+QvCB0r9QDIpAULx9PNBEL3DQfx2AUE7cK1BA6XmQc7Qq0GzqvNBefmjwcMcwkAW8NZA5dauQa5o6cDJ4KxBbzPBQSkX3EFNyIDANwObwIdZokH8dLdBhuaKPpiyE8FFDUTBeXvHQf/9vUE/SdlBY/+cwRSQq0Gc5JPBxul4wNERnMHhYtNBCiXSQYGFwkGYmd1BB/g4QRU+I0HnjxPB+BbzQQ/6UUCztgRChK9hP26c0kF7wG1B1A2JPkVir0Esa3XB95KhwR+yoD5qU70/5ITSwX3xlMBJMt9BXfSQQDvwDELlmSNCaoQAwGY1xEFY6/HBkQ5MQfaL1UFEUa5BBnC2wRC908E52onAKBTPQWvArMFs503AESaZQax6BUItHsdAEQ+awedZrsFC1ANBhHflQV1iwMDBiIVBCIDrQdWQgsG5MRrBr2onwHLMz0EPrsHBiKTqwDHem7/IxttAH725wa/DnUFGEiPCRdoRQqm+wEGosAhCWTDnwaHsC0LWd41B/tQCQhtZksG6AtRBkWDXQQi9DEEGOzZBalXNQSt51cEO54FBMkQyQSKKQMGHIZG/n+OTwa16scG2Y8PBC23QQbpNAUKFoglBSZHsQWPOHcLuh7ZB8EvWQKHG2kEzRpJBQpzmwfUTJ8DRahxBsdK6QWDb6cEBJVTBKBLHQVUrwUH7melADdqtv+3rHcEr+pvBCA+9wUEsksE=",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "E6HIQbKCBEJEU/5BmhD5QebDdEHpaUvAMdaXQIDbEMEHilfBWmmCQYMrQUBZ9rJBte3gQf9EokHYE4NBv2h3QcBiQUEDfLtBdchzQMtWm0ETn4xBCXmCwfnwiUGgGq5Amg2aQVlczkHMukFBRGiBQc0I70HYz81BS7+1QS4Y/0FlOrpBHrHYv0d66kEq8p6/5mjCQTGl5cFpVuxBYVmwPr8Oo8F38c3BNCoNQY4c8kGHWVVB7lKwQYRq4kDVb69BScwAQMi2+cHVBUe/mGq8QaE0sMGkm4DBYUSmQcZWIkGuyANCYLqqQSIL8cEqIgzBzTN7wRrCx0AaXtLBUqciQckPhkEYGQtBHH4VQaLnFMFCrytBq2tHQIfxjMEAP5dBhPKxQQ+ez0ESCZpBr9qbwRWYWsF/jfzBDt9xwVVfqcFWwbJBofKfQb9kS0HATXW/wK4KwV0EAEIUzOpBsce/QADgx8EkdELB80t3P4QgkUEvB8ZBh8LFwEnop0DEWqrBynWkwX5roUCrLinADcJzQVVA8EAYRMhBKbtLwUYX+76BLjtBbyjcQWZK9MHbdABBhvs8wUU5vkHO5fRB8fO+QLS4r0GnAIDBfrXIwW2CAEIPUuBBODFowVpKisGIPUc/Nqp3QTEqpT5T3QpB8ZYIQuhD2sHw3MhA1c4jQBm8nkHjGGvBIrZQQeixo0GMqeDBNUrbvxZV2cFdvqZB/CdDQH0Nz8BRI+g/LpvDQXl0BcFVOlVAhJimQa5YjsFDpAjCrQa5wU1yckDUGubBJwncQVyyskEEnZhBprMVwcxtMMF7Wv/BWZtawbXAgEFBc55B3GZaQcQNY0HVCJNBSsG3QFXKb0G+e0FBNCPpQPnb2UFNckRBfM08QQ3haUEPF6ZA1vQtQNOqBcHX3AVBIZmXwMpvEUJgJhNCvH99QWbun8HTgda/eZhBP7uNx8HIxfLAC8nUwdINwD5+ChbAGvotQHNVykGunOpBUP/TwKUo3EEvS1W/irhtwTCihEET5oFBafp6QfyNcUCZb77BIOP7QbltBsKHa5DBoEgaQeZr7kA=",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "model=CBOW<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>",
         "legendgroup": "CBOW",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "CBOW",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "harry",
          "said",
          "ron",
          "hermione",
          "back",
          "dumbledore",
          "could",
          "one",
          "like",
          "looked",
          "would",
          "know",
          "around",
          "well",
          "got",
          "professor",
          "see",
          "dont",
          "though",
          "think",
          "still",
          "time",
          "hagrid",
          "get",
          "right",
          "eyes",
          "wand",
          "looking",
          "snape",
          "face",
          "voice",
          "weasley",
          "going",
          "harrys",
          "look",
          "go",
          "didnt",
          "room",
          "im",
          "come",
          "head",
          "door",
          "thought",
          "mr",
          "something",
          "potter",
          "saw",
          "malfoy",
          "never",
          "behind",
          "seemed",
          "hand",
          "way",
          "away",
          "hes",
          "told",
          "asked",
          "turned",
          "two",
          "last",
          "toward",
          "much",
          "dark",
          "little",
          "us",
          "long",
          "even",
          "voldemort",
          "sirius",
          "knew",
          "first",
          "good",
          "want",
          "oh",
          "tell",
          "heard",
          "made",
          "people",
          "hogwarts",
          "left",
          "yes",
          "really",
          "say",
          "moment",
          "felt",
          "mrs",
          "youre",
          "fred",
          "great",
          "black",
          "might",
          "thats",
          "ive",
          "front",
          "ever",
          "came",
          "death",
          "feet",
          "take",
          "anything",
          "sure",
          "lupin",
          "next",
          "nothing",
          "took",
          "trying",
          "three",
          "make",
          "another",
          "cant",
          "let",
          "george",
          "yeah",
          "table",
          "open",
          "old",
          "ginny",
          "inside",
          "went",
          "find",
          "mcgonagall",
          "must",
          "course",
          "neville",
          "magic",
          "large",
          "put",
          "ill",
          "school",
          "floor",
          "upon",
          "every",
          "thing",
          "hall",
          "gave",
          "seen",
          "place",
          "found",
          "hands",
          "stood",
          "hear",
          "need",
          "night",
          "without",
          "ministry",
          "onto",
          "house",
          "uncle",
          "mean",
          "pulled",
          "end",
          "gryffindor",
          "years",
          "across",
          "quite",
          "hair",
          "wanted",
          "bit",
          "boy",
          "air",
          "hed",
          "wasnt",
          "better",
          "cloak",
          "done",
          "happened",
          "umbridge",
          "couldnt",
          "help",
          "side",
          "keep",
          "enough",
          "man",
          "rons",
          "second",
          "along",
          "bed",
          "give",
          "fudge",
          "mind",
          "wizard",
          "light",
          "yet",
          "already",
          "youve",
          "whats",
          "small",
          "vernon",
          "however",
          "year",
          "robes",
          "staring",
          "gone",
          "else",
          "many",
          "rather",
          "set",
          "walked",
          "fell",
          "forward"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": {
          "bdata": "Rbi1QbCWP8Fxl7ZB1nanQaF5u0F5C/VBa/g9Qp+bBj65xzNChxQTwsgJK0LEKBxCcp1ywfuhLEEYlKRBuqjHQY9hU0IyuCJB8pq4QYNtGUKdkY9BxRoxQHLma8F4ygVCnko2vzIJs8H+BFRBkUQXwtAO9UEoTNvBNtqWwUbaxEEq+kdB99BSQVUNsMGyvRFCHcMwQfloD8JprA9BdQ8XQoon60DmGD/CWpVLQk4DkcGcLBdCCYkGQkTTDcJSL4vBaNUlQlXOMsJONSpC1tzDQHYhHsJ4/SzCdzQPQfyr4EFfEk/Bd/FiwvdI0cDEPdFBPNYewuKZYEJF6SBCgcAYQq+yO8BMC+1BX4LZQW2TR0KE86VBmYkoQooOGkDzU5XB0A4nQhuPfUC3WyxCwxMowWcOOkKh/FPBVMYBQtEVocFfaEZB5JxTQd16FUIkQeHA9vnNQX6cosHenhRB4LkSwhA6SsJr7c3BNnsjQsTNDEEJOgPAckWlwfEf08B0lWLCHcT1QXtMKcJwUDlCTCA7QuRNJEISI/RBXI6YwVAGNkKHlqnAWWtiQjJX9r9OQEVCMf1VQk9CAkF5MTVB11Yewdq95EBRJyzCAh3pwbPvEsLbKsBBEARRwrwXE8KsyDZC3wjMQVMWGkJh6RtCc4alQVeAY0Gg7eLBbeUFQlEouUBWWvpBnVgNwlP1M0BKpQ1C0p0cQqVtKsJ8vOJA3DgyQtOk1UHlfRNCBhPSQEYdY8LdCFhC48opQr8uIkJcCONBFHyGQZLgQMLzSEVCg33vwTlf5kB1QWLAZe4swtWys8HGlDZA9FQmwi4oFUI3epXBIH81Qpp7F0ExwmbBkDg4wt66qsDHLDNBWLiLQVRwT8HoFMxBrDhZQizd40FdmEFCS/dOQku4V8KQgajBQHxWQIdlMsLrGFdB0lkPQb0+IsJ6ybvBf7AkQuvoYkHz8SdCAomZP7L6E8LXYUpCYwFoQScFlL9Ds5Q/gKuWwfDS88ErSjRCxPkWQqjOi8DyZgXC9YyswbkjV0I8VJpBeLQmQid6YMKA61vCieEPwsAVHUA=",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "PIxAQkN3nkEtRkZCUnVGQtQdPEI0Q69BwuUWwp1rC8JtnOdA1iYqQmkcF8IX7xHBaD4zQqG5I8D6mKvAbRuLwSJMX8HsMqbBA000QhStJMF4E1NCzRScwaKyasF544rBpkp+QMCiPUJmHgtCJicqQlY+vkEnvS1Ckl0IQkEP4kBjbKDAzwwTQpOSI0G21qvBOmSZwc6wl8EFp8m/S5OjwYo0QkJ2vjTBCth8wQPvXsIhCNXApDCGwVKqKUJqhA5CFVkovtFPwUGH74FBbRsoQq5vVMF9xZBBrXimwaHW8MAdFqhBYh9LQekB9sEaAIvBqDB7QQIPZcEE3VBBYvpSQY+Rt8E0yGDAOEMYwNXN4sG1uL/BSrVQQH7sasKwjGzBhV+6wLoyjUCk/TLBvm22Qc8XyUH0IQfCpGokwjyR4sHaxlFBlR2twDGTCsHzHxfC8qvRQR53X8IIFbm/I/UuwiM9UMH0yRlC0kYXwlSQgMC886jBt9aZQXq1xsE/ulxAtXLUwadapsEZYJnB8xbrP06tv8D9yMFB0e0Iwh42d79OUOxBHp96wX5O/sG4KVXBV/2vQfB2zMHS0LvBxW7nwYmyx0B6I7E+gzY4QqTx7MHDV0pCgoBXQGPY8UBtkl/BCbz5QWFYFMKzFjXAWuhNQkYVMcL/0WhASWEDwsL7vMG/7CrCFdIcQVypo0FvTj/CbOYfwp0Oo8A9EthBVCUtQMsGtsFqnbZAN9IpQnwyy0DgjXHBlBe+wGfXMsIetL1BWNFhwqDLVEGH04rB1dscQJCmab8f5dtBy6buwDb5NMKcX2DChL1qQU0VmUEy+N9BxPkWwsdfNkAywAnAvSFoQX4fRcEYPQ7BBZNCv5kfXEHvkenAlNyVQMsR60GAyBbCoJdpwdnzD0BS6pzB7Obzwe/iBkLJDt9BOZTYwaB6SUGqKAxBVeyTwfjXoUFjVE1A4z5LwsdS5kHCRF1ALm26wV1vqcELGqRB6jasQPdnL0CrT3pBQQwkwk5ggUG5BDdCwne7wULXskHYFxLCH3SvQb8/EsG7HO2+9KLCQeaXPEI=",
          "dtype": "f4"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "model"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Skip-gram vs CBOW Embeddings (proyección 2D)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar los embedddings en 2D\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import kaleido  # Necesario para guardar imágenes estáticas\n",
    "\n",
    "\n",
    "MAX_WORDS = 200\n",
    "\n",
    "# DataFrame para Skip-gram\n",
    "df_skip = pd.DataFrame({\n",
    "    \"x\": vecs_skip[:MAX_WORDS, 0],\n",
    "    \"y\": vecs_skip[:MAX_WORDS, 1],\n",
    "    \"word\": labels_skip[:MAX_WORDS],\n",
    "    \"model\": [\"Skip-gram\"] * MAX_WORDS\n",
    "})\n",
    "\n",
    "# DataFrame para CBOW\n",
    "df_cbow = pd.DataFrame({\n",
    "    \"x\": vecs_cbow[:MAX_WORDS, 0],\n",
    "    \"y\": vecs_cbow[:MAX_WORDS, 1],\n",
    "    \"word\": labels_cbow[:MAX_WORDS],\n",
    "    \"model\": [\"CBOW\"] * MAX_WORDS\n",
    "})\n",
    "\n",
    "# Concatenanar ambos DataFrames\n",
    "df_plot = pd.concat([df_skip, df_cbow])\n",
    "\n",
    "# Scatter plot con color por modelo\n",
    "fig = px.scatter(\n",
    "    df_plot, x=\"x\", y=\"y\", text=\"word\", color=\"model\",\n",
    "    title=\"Skip-gram vs CBOW Embeddings (proyección 2D)\"\n",
    ")\n",
    "\n",
    "fig.update_traces(textposition=\"top center\")  # move labels so they don’t overlap too much\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "blue",
          "size": 3
         },
         "mode": "markers+text",
         "name": "Skip-gram",
         "scene": "scene",
         "text": [
          "harry",
          "said",
          "ron",
          "hermione",
          "back",
          "dumbledore",
          "could",
          "one",
          "like",
          "looked",
          "would",
          "know",
          "around",
          "well",
          "got",
          "professor",
          "see",
          "dont",
          "though",
          "think",
          "still",
          "time",
          "hagrid",
          "get",
          "right",
          "eyes",
          "wand",
          "looking",
          "snape",
          "face",
          "voice",
          "weasley",
          "going",
          "harrys",
          "look",
          "go",
          "didnt",
          "room",
          "im",
          "come",
          "head",
          "door",
          "thought",
          "mr",
          "something",
          "potter",
          "saw",
          "malfoy",
          "never",
          "behind",
          "seemed",
          "hand",
          "way",
          "away",
          "hes",
          "told",
          "asked",
          "turned",
          "two",
          "last",
          "toward",
          "much",
          "dark",
          "little",
          "us",
          "long",
          "even",
          "voldemort",
          "sirius",
          "knew",
          "first",
          "good",
          "want",
          "oh",
          "tell",
          "heard",
          "made",
          "people",
          "hogwarts",
          "left",
          "yes",
          "really",
          "say",
          "moment",
          "felt",
          "mrs",
          "youre",
          "fred",
          "great",
          "black",
          "might",
          "thats",
          "ive",
          "front",
          "ever",
          "came",
          "death",
          "feet",
          "take",
          "anything",
          "sure",
          "lupin",
          "next",
          "nothing",
          "took",
          "trying",
          "three",
          "make",
          "another",
          "cant",
          "let",
          "george",
          "yeah",
          "table",
          "open",
          "old",
          "ginny",
          "inside",
          "went",
          "find",
          "mcgonagall",
          "must",
          "course",
          "neville",
          "magic",
          "large",
          "put",
          "ill",
          "school",
          "floor",
          "upon",
          "every",
          "thing",
          "hall",
          "gave",
          "seen",
          "place",
          "found",
          "hands",
          "stood",
          "hear",
          "need",
          "night",
          "without",
          "ministry",
          "onto",
          "house",
          "uncle",
          "mean",
          "pulled",
          "end",
          "gryffindor",
          "years",
          "across",
          "quite",
          "hair",
          "wanted",
          "bit",
          "boy",
          "air",
          "hed",
          "wasnt",
          "better",
          "cloak",
          "done",
          "happened",
          "umbridge",
          "couldnt",
          "help",
          "side",
          "keep",
          "enough",
          "man",
          "rons",
          "second",
          "along",
          "bed",
          "give",
          "fudge",
          "mind",
          "wizard",
          "light",
          "yet",
          "already",
          "youve",
          "whats",
          "small",
          "vernon",
          "however",
          "year",
          "robes",
          "staring",
          "gone",
          "else",
          "many",
          "rather",
          "set",
          "walked",
          "fell",
          "forward"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": {
          "bdata": "LUwoQTnNgkGL4SpB70Q1QHVPpsATF/dBxs0yQRonT0DecCNAeqJqwaH370FbsrtBkWLCwKs/rUEoxiBBkqKQQA5MP0HGRNBBwxUzQK1FwkEY37m/Nr4oQU2plEGA9qRBhahTQZwsAcLFyBLBLiBiwQFfksCNIcjBHzjzQOzOmkHnXPFBYt88wUGUEUBUM8ZBKTTiQYf0LMGN37dBeDKzQa3wfsHycbzB3rJ4QRQOmkG6dKpBSgn1QVyEa8FEJ/7AYBYEQhQbi8GfpyBBLE+mwRuc18AiTs7BgbzeQQRS2UEFeIlBAt+NwB1JcT9pIotBFIzGwYlU9EEfx65BQ+6KQG+67UFk+QvCB0r9QDIpAULx9PNBEL3DQfx2AUE7cK1BA6XmQc7Qq0GzqvNBefmjwcMcwkAW8NZA5dauQa5o6cDJ4KxBbzPBQSkX3EFNyIDANwObwIdZokH8dLdBhuaKPpiyE8FFDUTBeXvHQf/9vUE/SdlBY/+cwRSQq0Gc5JPBxul4wNERnMHhYtNBCiXSQYGFwkGYmd1BB/g4QRU+I0HnjxPB+BbzQQ/6UUCztgRChK9hP26c0kF7wG1B1A2JPkVir0Esa3XB95KhwR+yoD5qU70/5ITSwX3xlMBJMt9BXfSQQDvwDELlmSNCaoQAwGY1xEFY6/HBkQ5MQfaL1UFEUa5BBnC2wRC908E52onAKBTPQWvArMFs503AESaZQax6BUItHsdAEQ+awedZrsFC1ANBhHflQV1iwMDBiIVBCIDrQdWQgsG5MRrBr2onwHLMz0EPrsHBiKTqwDHem7/IxttAH725wa/DnUFGEiPCRdoRQqm+wEGosAhCWTDnwaHsC0LWd41B/tQCQhtZksG6AtRBkWDXQQi9DEEGOzZBalXNQSt51cEO54FBMkQyQSKKQMGHIZG/n+OTwa16scG2Y8PBC23QQbpNAUKFoglBSZHsQWPOHcLuh7ZB8EvWQKHG2kEzRpJBQpzmwfUTJ8DRahxBsdK6QWDb6cEBJVTBKBLHQVUrwUH7melADdqtv+3rHcEr+pvBCA+9wUEsksE=",
          "dtype": "f4"
         },
         "y": {
          "bdata": "E6HIQbKCBEJEU/5BmhD5QebDdEHpaUvAMdaXQIDbEMEHilfBWmmCQYMrQUBZ9rJBte3gQf9EokHYE4NBv2h3QcBiQUEDfLtBdchzQMtWm0ETn4xBCXmCwfnwiUGgGq5Amg2aQVlczkHMukFBRGiBQc0I70HYz81BS7+1QS4Y/0FlOrpBHrHYv0d66kEq8p6/5mjCQTGl5cFpVuxBYVmwPr8Oo8F38c3BNCoNQY4c8kGHWVVB7lKwQYRq4kDVb69BScwAQMi2+cHVBUe/mGq8QaE0sMGkm4DBYUSmQcZWIkGuyANCYLqqQSIL8cEqIgzBzTN7wRrCx0AaXtLBUqciQckPhkEYGQtBHH4VQaLnFMFCrytBq2tHQIfxjMEAP5dBhPKxQQ+ez0ESCZpBr9qbwRWYWsF/jfzBDt9xwVVfqcFWwbJBofKfQb9kS0HATXW/wK4KwV0EAEIUzOpBsce/QADgx8EkdELB80t3P4QgkUEvB8ZBh8LFwEnop0DEWqrBynWkwX5roUCrLinADcJzQVVA8EAYRMhBKbtLwUYX+76BLjtBbyjcQWZK9MHbdABBhvs8wUU5vkHO5fRB8fO+QLS4r0GnAIDBfrXIwW2CAEIPUuBBODFowVpKisGIPUc/Nqp3QTEqpT5T3QpB8ZYIQuhD2sHw3MhA1c4jQBm8nkHjGGvBIrZQQeixo0GMqeDBNUrbvxZV2cFdvqZB/CdDQH0Nz8BRI+g/LpvDQXl0BcFVOlVAhJimQa5YjsFDpAjCrQa5wU1yckDUGubBJwncQVyyskEEnZhBprMVwcxtMMF7Wv/BWZtawbXAgEFBc55B3GZaQcQNY0HVCJNBSsG3QFXKb0G+e0FBNCPpQPnb2UFNckRBfM08QQ3haUEPF6ZA1vQtQNOqBcHX3AVBIZmXwMpvEUJgJhNCvH99QWbun8HTgda/eZhBP7uNx8HIxfLAC8nUwdINwD5+ChbAGvotQHNVykGunOpBUP/TwKUo3EEvS1W/irhtwTCihEET5oFBafp6QfyNcUCZb77BIOP7QbltBsKHa5DBoEgaQeZr7kA=",
          "dtype": "f4"
         },
         "z": {
          "bdata": "Hy9Av5xCyz/iejZAtAfDQODH30DKoNLBZkj7wY4KMkF6SLfBYtjiwTZdKcFgvxJAAjCyQHxMUT/9VNRBDxkLwo8GmsC8W6JAvr6uwYCXIz/8a7tA/s/AQVdHuUEMGMBBD3zmwc/1uUAsvq9Bsqjowb7NWMEr8wlBqn2FwXAe28B245NAGHrywSu7LcGClMFBx4a0QDbKM0GLTB5BTMHEQbIq2UEX8a9A0henwd6NEcFm46fBaOUgwOC9qUE42LJBU8JKwcyHdEBJ1KjBYyMpwJj6n0AqKqdBC4pwQWgT30DIZgRAh58fQYtbK0FZdXxBp4SKQY62nUDuQ6dB2mXGwcW8WEHxeh/Ak9CgweuTssETHY/BdSuywcwT3UGYnc/AMUPDQN+xGr8QpBFAbUifwUrMBMLCO47BBViIQSgUh8AJVMvAQdWoQGvZzT+oZqPBL9bVwd8D3cDCbhpBsp8NQhPalMEapOpB2KOOQRO1W0HsU4xBasqlQb9fg8GtXZFBWlj1QVw4hEEVs7ZBjpiSQOLLbcG/pFHA+ubIQbI/78ENZ5zBX1nLQJlhJEEbT/HAqvwIwlAqBEEUZ5dBR5gNQg2LkUHWMcNBMB+LPzwIg8G+alpB72+OwQIxUUGs4JdBhyYLwjNZZ8GFkpvAfe4MQXGYWUAermDB6gCMQY7UkkE6wIZB9Q+YQajR10CerebAOzXTwcPigkFArUjBCLrpwVi3a0Eqk4JBX34xQFuLo0FtEQPC3c6XQXpv2MEnVIVBLKIQQMGndEE35i4+XjS/wXKuOT9qqnfBDQeUQQca+EGfgUdB4Z8/QQPZhcHGw3bAmZH8QBOhY0GxvAfBIntGQWdDU0GnG5DBs2NCQZthpsEnrGJAXp9uwX7t78Gyx/vB+B2MQY3bikHh7ORB0SEJQcVa+8C75RlBfkuHQQ1dZEEmgLlB9hO5QaP74UBNVsfBnP9SQGsI70C2htPB7yNEQU00iEEfZS9BwhGLwaFIv8GZzp3B8RqgQUNAisFf8PPBZS2GwebL4cFo1s3A5MrJwAEBzEDgR6JB+wGGQbctpkE=",
          "dtype": "f4"
         }
        },
        {
         "marker": {
          "color": "red",
          "size": 3
         },
         "mode": "markers+text",
         "name": "CBOW",
         "scene": "scene2",
         "text": [
          "harry",
          "said",
          "ron",
          "hermione",
          "back",
          "dumbledore",
          "could",
          "one",
          "like",
          "looked",
          "would",
          "know",
          "around",
          "well",
          "got",
          "professor",
          "see",
          "dont",
          "though",
          "think",
          "still",
          "time",
          "hagrid",
          "get",
          "right",
          "eyes",
          "wand",
          "looking",
          "snape",
          "face",
          "voice",
          "weasley",
          "going",
          "harrys",
          "look",
          "go",
          "didnt",
          "room",
          "im",
          "come",
          "head",
          "door",
          "thought",
          "mr",
          "something",
          "potter",
          "saw",
          "malfoy",
          "never",
          "behind",
          "seemed",
          "hand",
          "way",
          "away",
          "hes",
          "told",
          "asked",
          "turned",
          "two",
          "last",
          "toward",
          "much",
          "dark",
          "little",
          "us",
          "long",
          "even",
          "voldemort",
          "sirius",
          "knew",
          "first",
          "good",
          "want",
          "oh",
          "tell",
          "heard",
          "made",
          "people",
          "hogwarts",
          "left",
          "yes",
          "really",
          "say",
          "moment",
          "felt",
          "mrs",
          "youre",
          "fred",
          "great",
          "black",
          "might",
          "thats",
          "ive",
          "front",
          "ever",
          "came",
          "death",
          "feet",
          "take",
          "anything",
          "sure",
          "lupin",
          "next",
          "nothing",
          "took",
          "trying",
          "three",
          "make",
          "another",
          "cant",
          "let",
          "george",
          "yeah",
          "table",
          "open",
          "old",
          "ginny",
          "inside",
          "went",
          "find",
          "mcgonagall",
          "must",
          "course",
          "neville",
          "magic",
          "large",
          "put",
          "ill",
          "school",
          "floor",
          "upon",
          "every",
          "thing",
          "hall",
          "gave",
          "seen",
          "place",
          "found",
          "hands",
          "stood",
          "hear",
          "need",
          "night",
          "without",
          "ministry",
          "onto",
          "house",
          "uncle",
          "mean",
          "pulled",
          "end",
          "gryffindor",
          "years",
          "across",
          "quite",
          "hair",
          "wanted",
          "bit",
          "boy",
          "air",
          "hed",
          "wasnt",
          "better",
          "cloak",
          "done",
          "happened",
          "umbridge",
          "couldnt",
          "help",
          "side",
          "keep",
          "enough",
          "man",
          "rons",
          "second",
          "along",
          "bed",
          "give",
          "fudge",
          "mind",
          "wizard",
          "light",
          "yet",
          "already",
          "youve",
          "whats",
          "small",
          "vernon",
          "however",
          "year",
          "robes",
          "staring",
          "gone",
          "else",
          "many",
          "rather",
          "set",
          "walked",
          "fell",
          "forward"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": {
          "bdata": "Rbi1QbCWP8Fxl7ZB1nanQaF5u0F5C/VBa/g9Qp+bBj65xzNChxQTwsgJK0LEKBxCcp1ywfuhLEEYlKRBuqjHQY9hU0IyuCJB8pq4QYNtGUKdkY9BxRoxQHLma8F4ygVCnko2vzIJs8H+BFRBkUQXwtAO9UEoTNvBNtqWwUbaxEEq+kdB99BSQVUNsMGyvRFCHcMwQfloD8JprA9BdQ8XQoon60DmGD/CWpVLQk4DkcGcLBdCCYkGQkTTDcJSL4vBaNUlQlXOMsJONSpC1tzDQHYhHsJ4/SzCdzQPQfyr4EFfEk/Bd/FiwvdI0cDEPdFBPNYewuKZYEJF6SBCgcAYQq+yO8BMC+1BX4LZQW2TR0KE86VBmYkoQooOGkDzU5XB0A4nQhuPfUC3WyxCwxMowWcOOkKh/FPBVMYBQtEVocFfaEZB5JxTQd16FUIkQeHA9vnNQX6cosHenhRB4LkSwhA6SsJr7c3BNnsjQsTNDEEJOgPAckWlwfEf08B0lWLCHcT1QXtMKcJwUDlCTCA7QuRNJEISI/RBXI6YwVAGNkKHlqnAWWtiQjJX9r9OQEVCMf1VQk9CAkF5MTVB11Yewdq95EBRJyzCAh3pwbPvEsLbKsBBEARRwrwXE8KsyDZC3wjMQVMWGkJh6RtCc4alQVeAY0Gg7eLBbeUFQlEouUBWWvpBnVgNwlP1M0BKpQ1C0p0cQqVtKsJ8vOJA3DgyQtOk1UHlfRNCBhPSQEYdY8LdCFhC48opQr8uIkJcCONBFHyGQZLgQMLzSEVCg33vwTlf5kB1QWLAZe4swtWys8HGlDZA9FQmwi4oFUI3epXBIH81Qpp7F0ExwmbBkDg4wt66qsDHLDNBWLiLQVRwT8HoFMxBrDhZQizd40FdmEFCS/dOQku4V8KQgajBQHxWQIdlMsLrGFdB0lkPQb0+IsJ6ybvBf7AkQuvoYkHz8SdCAomZP7L6E8LXYUpCYwFoQScFlL9Ds5Q/gKuWwfDS88ErSjRCxPkWQqjOi8DyZgXC9YyswbkjV0I8VJpBeLQmQid6YMKA61vCieEPwsAVHUA=",
          "dtype": "f4"
         },
         "y": {
          "bdata": "PIxAQkN3nkEtRkZCUnVGQtQdPEI0Q69BwuUWwp1rC8JtnOdA1iYqQmkcF8IX7xHBaD4zQqG5I8D6mKvAbRuLwSJMX8HsMqbBA000QhStJMF4E1NCzRScwaKyasF544rBpkp+QMCiPUJmHgtCJicqQlY+vkEnvS1Ckl0IQkEP4kBjbKDAzwwTQpOSI0G21qvBOmSZwc6wl8EFp8m/S5OjwYo0QkJ2vjTBCth8wQPvXsIhCNXApDCGwVKqKUJqhA5CFVkovtFPwUGH74FBbRsoQq5vVMF9xZBBrXimwaHW8MAdFqhBYh9LQekB9sEaAIvBqDB7QQIPZcEE3VBBYvpSQY+Rt8E0yGDAOEMYwNXN4sG1uL/BSrVQQH7sasKwjGzBhV+6wLoyjUCk/TLBvm22Qc8XyUH0IQfCpGokwjyR4sHaxlFBlR2twDGTCsHzHxfC8qvRQR53X8IIFbm/I/UuwiM9UMH0yRlC0kYXwlSQgMC886jBt9aZQXq1xsE/ulxAtXLUwadapsEZYJnB8xbrP06tv8D9yMFB0e0Iwh42d79OUOxBHp96wX5O/sG4KVXBV/2vQfB2zMHS0LvBxW7nwYmyx0B6I7E+gzY4QqTx7MHDV0pCgoBXQGPY8UBtkl/BCbz5QWFYFMKzFjXAWuhNQkYVMcL/0WhASWEDwsL7vMG/7CrCFdIcQVypo0FvTj/CbOYfwp0Oo8A9EthBVCUtQMsGtsFqnbZAN9IpQnwyy0DgjXHBlBe+wGfXMsIetL1BWNFhwqDLVEGH04rB1dscQJCmab8f5dtBy6buwDb5NMKcX2DChL1qQU0VmUEy+N9BxPkWwsdfNkAywAnAvSFoQX4fRcEYPQ7BBZNCv5kfXEHvkenAlNyVQMsR60GAyBbCoJdpwdnzD0BS6pzB7Obzwe/iBkLJDt9BOZTYwaB6SUGqKAxBVeyTwfjXoUFjVE1A4z5LwsdS5kHCRF1ALm26wV1vqcELGqRB6jasQPdnL0CrT3pBQQwkwk5ggUG5BDdCwne7wULXskHYFxLCH3SvQb8/EsG7HO2+9KLCQeaXPEI=",
          "dtype": "f4"
         },
         "z": {
          "bdata": "DA++wHXMPMI8V97A89C3wD7gksC6CQXCXR6twGKhFcL7rJPBKNCDP2LssMA+duXBB3ESQu2MNsKuFEzCSu1KwjdHVsGPyVHCCmwMwQJY7cEItrFAhFQ5wsz4LcLZAQrCMdFHwnhepEHwkxxCIvRpP8BxIMLceq5BcUS0wauLSMIXWA7CtqWeQeUoV8IK2P3BW2xSwl2auUFTLGzCTYwCwkyjrkHmA8FBs5QpvmzKREHNX6jB9aLLwdbS+0BHkBzCVnN1wYMJ68Am1Z1By2PGQS0KwsHUYIFADJ4uwlKIA8Ir/zbCSdXXwONltUFQ7fVBMg3YP+TiG0EgjPvB3g4fQl9qL8Kf7xhC31SkwRN2TMHOV+PB0sRNwddYib1TaUrCsOwlwqYtJMIYTeLBUemzwVYNvMFz59PBZBlswXuWx0G5+SbCZkg+wtOs2ME7Tg9CtcVvQcTdG0FyyGjCujqNQNVGJsCULuZBcPS1wMsCQsIDbVbCq+RNQsDtPsI58DNBY0+LwdtFyUFfcJ3B9eqzwO5qhsHHQQjCZJuyQYdY1EDuqT1C70u5P4Ym4kEgXLzBxhzLQOaYTcIYxQXCu9hBQidKLsIT0QJCxUbswKaw9kEybPLAT1nbwcwEHMKmBtzBNh39wV6/AMF6CoLBzkgVwVfZZcEIBQtCTnXDQdmXTsKEmjnBZZQUQoa1wkGRt2HBMc/7QOrsmkEKupLBjWL/wAmZEsL7ugbCBRC/QTqXiEEnPlrBBZ0iwtFgX0GYaLdBb6TAP/tXLkGiZahBiS4ywkEEPML81SRC1VQZQSZbLz9bQLXAIpC7QOZeDb6LUvNBSfGqwA5vOMJ2E1DCp7ayQXLFVcJUrTrC6KY9wgsmQ0JsyzHCxaciwcgS/MEEEa7Ap7iQwQF30UE3uBzCqyX9wY0g9sDGZAVCfWSEQRlU9j9m81RCoobMwQFRNMIoEZJBdc9mwViov0HIM2M/h7p4wUYsT8IF/U7CiuELQpxEFMIZZPxAmOBMQPaTH0Kvk82/2UBGwkbJCMH06QZCHMCPwW5bPkAlvm3AkO8OQsvXEkI=",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Skip-gram Embeddings",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "CBOW Embeddings",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 700,
        "scene": {
         "domain": {
          "x": [
           0,
           0.45
          ],
          "y": [
           0,
           1
          ]
         }
        },
        "scene2": {
         "domain": {
          "x": [
           0.55,
           1
          ],
          "y": [
           0,
           1
          ]
         }
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Skip-gram vs CBOW Word Embeddings (3D Projection)",
         "x": 0.5
        },
        "width": 1400
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import kaleido  # Necesario para guardar imágenes estáticas\n",
    "\n",
    "MAX_WORDS = 200\n",
    "\n",
    "# Reducir Skip-gram y CBOW a 3D\n",
    "vecs_skip, labels_skip = reduce_dimensions(model_hp_potter, 3)\n",
    "vecs_cbow, labels_cbow = reduce_dimensions(model_hp_potter_cbow, 3)\n",
    "\n",
    "#  DataFrame para Skip-gram\n",
    "df_skip = pd.DataFrame({\n",
    "    \"x\": vecs_skip[:MAX_WORDS, 0],\n",
    "    \"y\": vecs_skip[:MAX_WORDS, 1],\n",
    "    \"z\": vecs_skip[:MAX_WORDS, 2],\n",
    "    \"word\": labels_skip[:MAX_WORDS]\n",
    "})\n",
    "\n",
    "#  DataFrame para CBOW\n",
    "df_cbow = pd.DataFrame({\n",
    "    \"x\": vecs_cbow[:MAX_WORDS, 0],\n",
    "    \"y\": vecs_cbow[:MAX_WORDS, 1],\n",
    "    \"z\": vecs_cbow[:MAX_WORDS, 2],\n",
    "    \"word\": labels_cbow[:MAX_WORDS]\n",
    "})\n",
    "\n",
    "# Crear los subplots 3d\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]],\n",
    "    subplot_titles=('Skip-gram Embeddings', 'CBOW Embeddings'),\n",
    "    horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "# agregar  Skip-gram scatter plot\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=df_skip[\"x\"],\n",
    "        y=df_skip[\"y\"],\n",
    "        z=df_skip[\"z\"],\n",
    "        mode='markers+text',\n",
    "        text=df_skip[\"word\"],\n",
    "        textposition='middle center',\n",
    "        marker=dict(size=3, color='blue'),\n",
    "        name='Skip-gram'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# agregar CBOW scatter plot\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=df_cbow[\"x\"],\n",
    "        y=df_cbow[\"y\"],\n",
    "        z=df_cbow[\"z\"],\n",
    "        mode='markers+text',\n",
    "        text=df_cbow[\"word\"],\n",
    "        textposition='middle center',\n",
    "        marker=dict(size=3, color='red'),\n",
    "        name='CBOW'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_text=\"Skip-gram vs CBOW Word Embeddings (3D Projection)\",\n",
    "    title_x=0.5,\n",
    "    showlegend=True,\n",
    "    width=1400,\n",
    "    height=700\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# PNG (static image - requires kaleido package)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "El proceso de preprocesamiento y limpieza del dataset tuvo un impacto significativo en la calidad del texto utilizado para entrenar el modelo de *Word2Vec*.  \n",
    "\n",
    "1. Reducción del vocabulario:\n",
    "   - Tokens únicos antes de la limpieza: **2238**  \n",
    "   - Tokens únicos después de la limpieza: **1628**  \n",
    "   → Esto representa una reducción del **27%** en el tamaño del vocabulario, eliminando ruido y variaciones innecesarias (puntuación, mayúsculas, etc.).\n",
    "\n",
    "2. Manejo de stopwords: \n",
    "   - Stopwords detectadas sin normalización: **6723**  \n",
    "   - Stopwords detectadas después de la limpieza: **7053**  \n",
    "   → La limpieza permitió una correcta identificación de stopwords, que inicialmente estaban ocultas por diferencias de formato (puntuación, capitalización).  \n",
    "\n",
    "3. Estandarización del texto: \n",
    "   La conversión a minúsculas y la eliminación de caracteres no alfabéticos aseguraron que palabras semánticamente idénticas no fueran contadas como tokens diferentes.\n",
    "\n",
    "4. Impacto en el modelo: \n",
    "   - El modelo de *Word2Vec* se entrenó sobre un corpus más consistente y menos ruidoso.  \n",
    "   - Esto favorece que las representaciones vectoriales reflejen relaciones semánticas reales en lugar de artefactos de formato.\n",
    " En conclusión, el preprocesamiento no solo redujo el ruido en los datos, sino que también mejoró la representatividad semántica del corpus, logrando un vocabulario más compacto y útil para el entrenamiento de modelos de NLP.  \n",
    "\n",
    "5. Relaciones entre palabras:\n",
    "   - El modelo predice una relación correcta al elegir los nombres de personajes principales, o lugares de interés en los cuentos, lo que demuestra que se capturó adecuadamente el contexto de la obra.\n",
    "     - Harry es asociado principalmente con sus mejores amigos\n",
    "     - Voldemort con \"lord\" dado que siempre es referido como \"Lord Voldermort\" en las historias\n",
    "     - Station, es referenciada a la estación en Londres donde se puede abordar el tren mágico rumbo a la escuela de magos.\n",
    "\n",
    "6. Análisis de gráficos:\n",
    "     - En el gráfico 2D se observan clusters de mayor cantidad de objetos de color azul, mientras que el rojo (Cbow) en general son puntos mas dispersos.\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (CEIA-NLP)",
   "language": "python",
   "name": "ceia-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
